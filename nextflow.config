// nextflow.config: Main Configuration for AoU H1/H2 Association Pipeline (Hail/Dataproc)

// --- Global Pipeline Parameters ---
params {
    // Input Data & Definitions (REQUIRED - User MUST provide valid values OR rely on AoU env vars)
    cdr_dataset_id            = System.getenv('WORKSPACE_CDR')
    wgs_vds_path              = System.getenv('WGS_VDS_PATH') ?: 'gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/vds/hail.vds'
    output_dir_gcs            = System.getenv('WORKSPACE_BUCKET') ? "${System.getenv('WORKSPACE_BUCKET')}/results/aou_h1h2_assoc_nf" : null

    // --- Phenotype Definitions (Defaults based on notebook Cell 1) ---
    disease_definitions_json = """
    {
        "PSP": {"icd_patterns": ["G23.1%"], "source": "ICD Codes: G23.1%"},
        "CBD": {"icd_patterns": ["G31.85%"], "source": "ICD Codes: G31.85%"},
        "PD": {"icd_patterns": ["G20%"], "source": "ICD Codes: G20%"},
        "AD": {"icd_patterns": ["G30.%"], "source": "ICD Codes: G30.%"},
        "FTD": {"icd_patterns": ["G31.0%"], "source": "ICD Codes: G31.0%"},
        "DevDelay": {"icd_patterns": ["R62.5%"], "source": "ICD Codes: R62.5%"},
        "IntelDisab": {"icd_patterns": ["F70.%","F71.%","F72.%","F73.%","F74.%","F75.%","F76.%","F77.%","F78.%","F79.%"], "source": "ICD Codes: F70-F79%"},
        "LearnDisab": {"icd_patterns": ["F81.%"], "source": "ICD Codes: F81.%"},
        "ASD": {"icd_patterns": ["F84.0%"], "source": "ICD Codes: F84.0%"},
        "Osteoarthr": {"icd_patterns": ["M15.%","M16.%","M17.%","M18.%","M19.%"], "source": "ICD Codes: M15-M19%"},
        "COPD": {"icd_patterns": ["J44.%"], "source": "ICD Codes: J44.%"},
        "Depression": {"icd_patterns": ["F32.%", "F33.%"], "source": "ICD Codes: F32.%, F33.%"}
    }
    """
    neuro_diseases_list       = ['PSP', 'CBD', 'PD', 'AD', 'FTD']

    // --- Target SNP Definitions ---
    target_snps_list          = ['chr17:45996523', 'chr17:45974480', 'chr17:46024197']
    target_snp_alleles_json   = """
    {
        "chr17:45996523": {"H1": "A", "H2": "G"},
        "chr17:45974480": {"H1": "A", "H2": "G"},
        "chr17:46024197": {"H1": "T", "H2": "C"}
    }
    """
    // --- Process Resource Defaults (CLS tasks) ---
    assoc_calc_mem            = '8.GB'
    assoc_calc_disk           = '50.GB'
    assoc_calc_time           = '1.h'

    bq_query_mem              = '8.GB'
    bq_query_disk             = '50.GB'
    bq_query_time             = '2.h'

    // --- Dataproc Cluster Configuration ---
    dataproc_region           = 'us-central1'
    // Generate unique name based on workflow session ID for better tracking
    dataproc_cluster_name     = "nf-hail-${workflow.sessionId.replaceAll('-', '').toLowerCase()[0..15]}"
    dataproc_master_machine   = 'n1-standard-8' // default based on densify needs
    dataproc_master_disk_gb   = 150
    dataproc_worker_machine   = 'n1-standard-8' // default
    dataproc_num_workers      = 2
    dataproc_worker_disk_gb   = 150
    dataproc_image_version    = '2.1-debian11'
    // Note: We don't pin the Hail version param strictly, rely on the image's default Hail. Script checks version.
    dataproc_init_script      = null
    dataproc_max_idle_min     = 10

    // --- Help Parameter ---
    help                      = false
}

// Container Specification
// Derives GCR path from the Google Project environment variable
def custom_python_container = {
    def gcp_project = System.getenv('GOOGLE_PROJECT')
    if (!gcp_project) {
        error "GOOGLE_PROJECT environment variable is not set. Cannot determine container path."
    }
    return "gcr.io/${gcp_project}/aou-h1h2-assoc-py:latest" // Use specific tag like '-py'
}()


// --- Process Defaults ---
process {
    errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
    maxRetries    = 1
    maxErrors     = '-1'
    cpus   = 1
    memory = '8.GB'
    time   = '6.h'
}

// --- Docker Configuration (for CLS executor) ---
docker {
    enabled = true
    runOptions = '--network host' // Required for ADC in AoU VPC-SC
}

// --- Profiles ---
profiles {
    standard {
        process.cpus   = 1
        process.memory = params.bq_query_mem
        process.time   = '6.h'
    }

    google {
        process {
            executor = 'google-cls' // Default executor
            withName: DEFINE_COHORT          { container = custom_python_container }
            withName: EXTRACT_CONSENSUS_DATAPROC { executor = 'google-dataproc'; /* No container needed here */ }
            withName: CALCULATE_ASSOCIATION  { container = custom_python_container }
        }
        google { // CLS Settings
            project = System.getenv('GOOGLE_PROJECT')
            region  = params.dataproc_region
            lifeSciences {
                 bootDiskSize = '50.GB'
                 preemptible = false
            }
            network    = 'network'
            subnetwork = 'subnetwork'
        }
        google.dataproc { // Dataproc Settings
            region          = params.dataproc_region
            clusterName     = params.dataproc_cluster_name
            masterMachineType = params.dataproc_master_machine
            masterDiskSize  = "${params.dataproc_master_disk_gb}.GB"
            workerMachineType = params.dataproc_worker_machine
            numWorkers      = params.dataproc_num_workers
            workerDiskSize  = "${params.dataproc_worker_disk_gb}.GB"
            imageVersion    = params.dataproc_image_version
            // Rely on Hail version from image, properties only for zero workers if needed
            properties      = "dataproc:dataproc.allow.zero.workers=false"
            initializationActions = params.dataproc_init_script ? [params.dataproc_init_script] : []
            network         = 'network'
            subnetwork      = 'subnetwork'
            maxIdle         = "${params.dataproc_max_idle_min}m"
        }
        wave.enabled   = false
        fusion.enabled = false
    }
}

// --- Other Settings ---
manifest {
    name        = 'aou-h1h2-association-dataproc-py'
    description = 'Nextflow pipeline for H1/H2 MAPT haplotype association (Hail on Dataproc, Python/Pandas/SciPy on CLS)'
    version     = '0.1.0'
}

// Function to print help message
def helpMessage() {
    log.info"""
    Usage:
    nextflow run main.nf -profile google [pipeline options]

    Required Parameters (will attempt to use AoU environment variables if not provided):
    --cdr_dataset_id          : Google Cloud Project ID for the AoU CDR dataset (e.g., WORKSPACE_CDR env var)
    --output_dir_gcs          : GCS path for pipeline output directory (e.g., WORKSPACE_BUCKET env var + /results/...)

    Optional Parameters:
    --wgs_vds_path            : GCS path to the source WGS VDS (Default: AoU v7 path)
    --disease_definitions_json : JSON string or path to JSON file defining diseases and ICD codes (Default: provided in config)
    --neuro_diseases_list     : Comma-separated string of diseases considered 'neuro' for control definition (Default: provided in config)
    --target_snps_list        : Comma-separated string of target SNP IDs (chr:pos format) (Default: 3 MAPT SNPs)
    --target_snp_alleles_json : JSON string or path to JSON file defining H1/H2 alleles for target SNPs (Default: provided in config)
    --dataproc_num_workers    : Number of worker nodes for Hail job (Default: ${params.dataproc_num_workers})
    --dataproc_master_machine : Machine type for Dataproc master (Default: ${params.dataproc_master_machine})
    --dataproc_worker_machine : Machine type for Dataproc workers (Default: ${params.dataproc_worker_machine})
    --help                    : Display this help message and exit
    """.stripIndent()
}

// Show help message if --help is provided
if (params.help) {
    helpMessage()
    exit 0
}

// Validate required parameters that couldn't be derived from environment
if (!params.cdr_dataset_id) exit 1, "Missing required parameter: --cdr_dataset_id (or set WORKSPACE_CDR env var)"
if (!params.output_dir_gcs) exit 1, "Missing required parameter: --output_dir_gcs (or set WORKSPACE_BUCKET env var)"

// Validate GCR path derivation
// Check if GOOGLE_PROJECT env var was set for container path construction
if (!System.getenv('GOOGLE_PROJECT')) {
    exit 1, "ERROR: GOOGLE_PROJECT environment variable is not set. Cannot construct container path."
}
